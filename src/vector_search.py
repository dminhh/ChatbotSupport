"""
Vector Search module s·ª≠ d·ª•ng FAISS v√† OpenAI Embeddings.
Implement RAG (Retrieval-Augmented Generation) cho chatbot FAQ.
"""

import json
import pickle
import os
from typing import List, Dict, Tuple
import numpy as np
import faiss
from openai import OpenAI


class VectorSearch:
    """
    Qu·∫£n l√Ω vector search v·ªõi FAISS index v√† OpenAI Embeddings.

    Flow:
    1. Build index: Encode t·∫•t c·∫£ FAQ ‚Üí FAISS index (1 l·∫ßn)
    2. Search: Encode query ‚Üí FAISS search ‚Üí Top-k similar FAQs
    """

    def __init__(
        self,
        kb_path: str,
        index_path: str = "data/faiss_index.bin",
        metadata_path: str = "data/metadata.pkl",
        embedding_model: str = "text-embedding-3-small",
        dimension: int = 1536
    ):
        """
        Kh·ªüi t·∫°o VectorSearch.

        Args:
            kb_path: ƒê∆∞·ªùng d·∫´n t·ªõi knowledge_base.json
            index_path: ƒê∆∞·ªùng d·∫´n l∆∞u FAISS index
            metadata_path: ƒê∆∞·ªùng d·∫´n l∆∞u metadata (questions, answers)
            embedding_model: Model OpenAI Embeddings
            dimension: S·ªë chi·ªÅu c·ªßa vector (1536 cho text-embedding-3-small)
        """
        self.kb_path = kb_path
        self.index_path = index_path
        self.metadata_path = metadata_path
        self.embedding_model = embedding_model
        self.dimension = dimension

        # Kh·ªüi t·∫°o OpenAI client
        self.client = OpenAI()

        # Load ho·∫∑c build index
        self.index, self.metadata = self._load_or_build_index()

    def _create_embedding(self, text: str) -> np.ndarray:
        """
        T·∫°o embedding vector t·ª´ text s·ª≠ d·ª•ng OpenAI API.

        Args:
            text: VƒÉn b·∫£n c·∫ßn encode

        Returns:
            numpy array shape (dimension,)
        """
        response = self.client.embeddings.create(
            model=self.embedding_model,
            input=text
        )
        embedding = response.data[0].embedding
        return np.array(embedding, dtype=np.float32)

    def _create_embeddings_batch(self, texts: List[str]) -> np.ndarray:
        """
        T·∫°o embeddings cho nhi·ªÅu texts (batch).

        Args:
            texts: List c√°c vƒÉn b·∫£n

        Returns:
            numpy array shape (len(texts), dimension)
        """
        response = self.client.embeddings.create(
            model=self.embedding_model,
            input=texts
        )
        embeddings = [item.embedding for item in response.data]
        return np.array(embeddings, dtype=np.float32)

    def _load_knowledge_base(self) -> Dict:
        """Load knowledge base t·ª´ JSON."""
        with open(self.kb_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _build_index(self) -> Tuple[faiss.Index, Dict]:
        """
        Build FAISS index t·ª´ knowledge base.

        Returns:
            (FAISS index, metadata dict)
        """
        print("üî® Building FAISS index...")

        # Load KB
        kb = self._load_knowledge_base()

        # Chu·∫©n b·ªã data
        questions = []
        answers = []
        categories = []

        for category in kb['categories']:
            category_name = category['name']
            for qa in category['questions']:
                questions.append(qa['question'])
                answers.append(qa['answer'])
                categories.append(category_name)

        print(f"üìö Loaded {len(questions)} FAQs from {len(kb['categories'])} categories")

        # T·∫°o embeddings cho t·∫•t c·∫£ c√¢u h·ªèi (batch ƒë·ªÉ nhanh h∆°n)
        print("üîÑ Creating embeddings...")
        embeddings = self._create_embeddings_batch(questions)

        # T·∫°o FAISS index
        # IndexFlatL2: Simple, exact search v·ªõi L2 distance
        index = faiss.IndexFlatL2(self.dimension)
        index.add(embeddings)

        print(f"‚úÖ Index built with {index.ntotal} vectors")

        # Metadata
        metadata = {
            'questions': questions,
            'answers': answers,
            'categories': categories,
            'total': len(questions)
        }

        # L∆∞u index v√† metadata
        self._save_index(index, metadata)

        return index, metadata

    def _save_index(self, index: faiss.Index, metadata: Dict):
        """L∆∞u FAISS index v√† metadata ra disk."""
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
        os.makedirs(os.path.dirname(self.index_path), exist_ok=True)

        # L∆∞u FAISS index
        faiss.write_index(index, self.index_path)

        # L∆∞u metadata
        with open(self.metadata_path, 'wb') as f:
            pickle.dump(metadata, f)

        print(f"üíæ Saved index to {self.index_path}")
        print(f"üíæ Saved metadata to {self.metadata_path}")

    def _load_index(self) -> Tuple[faiss.Index, Dict]:
        """Load FAISS index v√† metadata t·ª´ disk."""
        print("üìÇ Loading existing index...")

        # Load FAISS index
        index = faiss.read_index(self.index_path)

        # Load metadata
        with open(self.metadata_path, 'rb') as f:
            metadata = pickle.load(f)

        print(f"‚úÖ Loaded index with {index.ntotal} vectors")

        return index, metadata

    def _load_or_build_index(self) -> Tuple[faiss.Index, Dict]:
        """Load index n·∫øu c√≥, kh√¥ng th√¨ build m·ªõi."""
        if os.path.exists(self.index_path) and os.path.exists(self.metadata_path):
            try:
                return self._load_index()
            except Exception as e:
                print(f"‚ö†Ô∏è Error loading index: {e}")
                print("üî® Rebuilding index...")
                return self._build_index()
        else:
            return self._build_index()

    def rebuild_index(self):
        """Force rebuild index (khi update knowledge base)."""
        self.index, self.metadata = self._build_index()

    def search(
        self,
        query: str,
        top_k: int = 3,
        distance_threshold: float = None
    ) -> List[Dict]:
        """
        T√¨m ki·∫øm FAQs t∆∞∆°ng t·ª± v·ªõi query.

        Args:
            query: C√¢u h·ªèi t·ª´ user
            top_k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ
            distance_threshold: Ng∆∞·ª°ng kho·∫£ng c√°ch t·ªëi ƒëa (None = kh√¥ng filter)

        Returns:
            List c√°c FAQ v·ªõi format:
            [
                {
                    'question': str,
                    'answer': str,
                    'category': str,
                    'distance': float,  # L2 distance (c√†ng nh·ªè c√†ng gi·ªëng)
                    'similarity': float  # 0-1 (c√†ng cao c√†ng gi·ªëng)
                }
            ]
        """
        # Encode query
        query_vector = self._create_embedding(query)
        query_vector = query_vector.reshape(1, -1)  # Shape: (1, dimension)

        # Search trong FAISS
        distances, indices = self.index.search(query_vector, top_k)

        # Build results
        results = []
        for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
            # Filter theo threshold n·∫øu c√≥
            if distance_threshold is not None and dist > distance_threshold:
                continue

            # Convert L2 distance sang similarity score (0-1)
            # Distance c√†ng nh·ªè ‚Üí similarity c√†ng cao
            # D√πng c√¥ng th·ª©c: similarity = 1 / (1 + distance)
            similarity = 1.0 / (1.0 + dist)

            results.append({
                'question': self.metadata['questions'][idx],
                'answer': self.metadata['answers'][idx],
                'category': self.metadata['categories'][idx],
                'distance': float(dist),
                'similarity': float(similarity),
                'rank': i + 1
            })

        return results

    def get_stats(self) -> Dict:
        """L·∫•y th·ªëng k√™ v·ªÅ index."""
        return {
            'total_vectors': self.index.ntotal,
            'dimension': self.dimension,
            'model': self.embedding_model,
            'total_questions': self.metadata['total'],
            'categories': list(set(self.metadata['categories']))
        }


if __name__ == "__main__":
    # Test code
    vs = VectorSearch(kb_path="data/knowledge_base.json")

    # Test search
    test_queries = [
        "Giao h√†ng m·∫•t bao l√¢u?",
        "Bao gi·ªù t√¥i nh·∫≠n ƒë∆∞·ª£c ƒë∆°n?",
        "Ship c√≥ m·∫•t ph√≠ kh√¥ng?",
        "L√†m sao ƒë·ªÉ theo d√µi ƒë∆°n h√†ng?"
    ]

    print("\n" + "="*60)
    print("TEST VECTOR SEARCH")
    print("="*60)

    for query in test_queries:
        print(f"\nüîç Query: '{query}'")
        results = vs.search(query, top_k=2)

        for r in results:
            print(f"  [{r['rank']}] Similarity: {r['similarity']:.3f}")
            print(f"      Q: {r['question']}")
            print(f"      Category: {r['category']}")
