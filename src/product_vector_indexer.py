"""
Product Vector Indexer - Vector h√≥a products v√† build FAISS index.
L∆∞u vectors v√†o b·∫£ng product_vectors trong MySQL.

Flow m·ªõi:
1. L·∫•y ·∫£nh n·ªÅn (ANH_NEN) c·ªßa products t·ª´ b·∫£ng images
2. Ph√¢n t√≠ch ·∫£nh b·∫±ng LLM Vision ‚Üí JSON {product_name, keywords, description}
3. T·∫°o text m√¥ t·∫£ t·ª´ JSON
4. Embedding text m√¥ t·∫£ v√† l∆∞u v√†o product_vectors
"""

import json
import os
import pickle
from typing import List, Dict, Optional
import numpy as np
import faiss
from openai import OpenAI
import mysql.connector
from mysql.connector import Error


class ProductVectorIndexer:
    """
    Qu·∫£n l√Ω vi·ªác vector h√≥a products v√† build FAISS index.

    Flow:
    1. L·∫•y products t·ª´ b·∫£ng products (id, title)
    2. Vector h√≥a title b·∫±ng OpenAI Embeddings
    3. L∆∞u vectors v√†o b·∫£ng product_vectors (JSON format)
    4. Build FAISS index t·ª´ product_vectors
    """

    def __init__(
        self,
        db_config: Dict[str, str],
        embedding_model: str = "text-embedding-3-small",
        dimension: int = 1536,
        index_path: str = "data/product_index.bin",
        metadata_path: str = "data/product_metadata.pkl"
    ):
        """
        Kh·ªüi t·∫°o ProductVectorIndexer.

        Args:
            db_config: Dictionary ch·ª©a th√¥ng tin k·∫øt n·ªëi database
                {
                    'host': 'localhost',
                    'port': 3306,
                    'database': 'ecommerce',
                    'user': 'root',
                    'password': 'password'
                }
            embedding_model: Model OpenAI Embeddings
            dimension: S·ªë chi·ªÅu c·ªßa vector (1536 cho text-embedding-3-small)
            index_path: ƒê∆∞·ªùng d·∫´n l∆∞u FAISS index
            metadata_path: ƒê∆∞·ªùng d·∫´n l∆∞u metadata (product_ids, titles)
        """
        self.db_config = db_config
        self.embedding_model = embedding_model
        self.dimension = dimension
        self.index_path = index_path
        self.metadata_path = metadata_path

        # Kh·ªüi t·∫°o OpenAI client
        self.client = OpenAI()

        # FAISS index v√† metadata
        self.index: Optional[faiss.Index] = None
        self.product_ids: List[int] = []
        self.titles: List[str] = []

        # Load index n·∫øu c√≥
        self._load_index_if_exists()

    def _get_db_connection(self):
        """T·∫°o k·∫øt n·ªëi ƒë·∫øn MySQL database."""
        try:
            connection = mysql.connector.connect(
                host=self.db_config['host'],
                port=self.db_config.get('port', 3306),
                database=self.db_config['database'],
                user=self.db_config['user'],
                password=self.db_config['password']
            )

            if connection.is_connected():
                return connection
        except Error as e:
            print(f"‚ùå L·ªói k·∫øt n·ªëi MySQL: {e}")
            raise

    def _analyze_image_from_url(self, image_url: str) -> Optional[Dict]:
        """
        Ph√¢n t√≠ch ·∫£nh s·∫£n ph·∫©m b·∫±ng LLM Vision t·ª´ URL.
        S·ª≠ d·ª•ng C√ôNG format nh∆∞ ProductVisualSearch ƒë·ªÉ ƒë·∫£m b·∫£o consistency.

        Args:
            image_url: URL c√¥ng khai c·ªßa ·∫£nh s·∫£n ph·∫©m

        Returns:
            Dictionary ch·ª©a product_name, keywords, description
            {
                "product_name": "...",
                "keywords": [...],
                "description": "..."
            }
            Ho·∫∑c None n·∫øu c√≥ l·ªói
        """
        system_prompt = """B·∫°n l√† AI chuy√™n ph√¢n t√≠ch ·∫£nh s·∫£n ph·∫©m th·ªùi trang v√† ƒë·ªì d√πng.

Nhi·ªám v·ª•: Ph√¢n t√≠ch ·∫£nh v√† tr·∫£ v·ªÅ th√¥ng tin s·∫£n ph·∫©m d·∫°ng JSON.

Output format (JSON):
{
  "product_name": "T√™n s·∫£n ph·∫©m ng·∫Øn g·ªçn",
  "keywords": ["keyword1", "keyword2", ...],
  "description": "M√¥ t·∫£ chi ti·∫øt s·∫£n ph·∫©m"
}

Y√™u c·∫ßu:
- product_name: T√™n s·∫£n ph·∫©m ch√≠nh x√°c, ng·∫Øn g·ªçn (VD: "√Åo s∆° mi tay d√†i", "Qu·∫ßn jean nam")
- keywords: 5-10 t·ª´ kh√≥a li√™n quan (ti·∫øng Vi·ªát), bao g·ªìm:
  + Lo·∫°i s·∫£n ph·∫©m
  + Phong c√°ch (casual, formal, streetwear, etc.)
  + M√†u s·∫Øc
  + Ch·∫•t li·ªáu (n·∫øu nh√¨n th·∫•y)
  + ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t
  + T·ª´ kh√≥a t√¨m ki·∫øm ph·ªï bi·∫øn
- description: M√¥ t·∫£ chi ti·∫øt v·ªÅ s·∫£n ph·∫©m (m√†u s·∫Øc, ki·ªÉu d√°ng, phong c√°ch, d·ªãp s·ª≠ d·ª•ng)

L∆∞u √Ω:
- Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng gi·∫£i th√≠ch th√™m
- N·∫øu kh√¥ng ph·∫£i s·∫£n ph·∫©m th·ªùi trang/ƒë·ªì d√πng, tr·∫£ v·ªÅ null"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Ph√¢n t√≠ch ·∫£nh s·∫£n ph·∫©m n√†y v√† tr·∫£ v·ªÅ JSON nh∆∞ y√™u c·∫ßu."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": image_url
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500,
                temperature=0.3
            )

            # Parse JSON response
            content = response.choices[0].message.content.strip()

            # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p LLM tr·∫£ v·ªÅ markdown code block
            if content.startswith('```'):
                content = content.replace('```json', '').replace('```', '').strip()

            result = json.loads(content)

            # Validate output
            if result and 'product_name' in result and 'keywords' in result and 'description' in result:
                return result
            else:
                print(f"‚ö†Ô∏è LLM output thi·∫øu fields cho {image_url}")
                return None

        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è L·ªói parse JSON t·ª´ LLM cho {image_url}: {e}")
            return None
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi ph√¢n t√≠ch ·∫£nh {image_url}: {e}")
            return None

    def _create_description_text(self, llm_output: Dict) -> str:
        """
        T·∫°o text m√¥ t·∫£ t·ª´ LLM output.
        S·ª≠ d·ª•ng C√ôNG logic nh∆∞ ProductVisualSearch.create_search_query().

        Args:
            llm_output: Dictionary t·ª´ _analyze_image_from_url()

        Returns:
            Text m√¥ t·∫£ ƒë·ªÉ embedding
        """
        product_name = llm_output.get('product_name', '')
        description = llm_output.get('description', '')
        keywords = llm_output.get('keywords', [])

        # K·∫øt h·ª£p: product_name + description + top keywords
        parts = [product_name, description]

        # Th√™m top 5 keywords
        if keywords:
            parts.append(' '.join(keywords[:5]))

        text = ' '.join(parts)
        return text

    def _create_embeddings_batch(self, texts: List[str]) -> np.ndarray:
        """
        T·∫°o embeddings cho nhi·ªÅu texts (batch).

        Args:
            texts: List c√°c vƒÉn b·∫£n

        Returns:
            numpy array shape (len(texts), dimension)
        """
        response = self.client.embeddings.create(
            model=self.embedding_model,
            input=texts
        )
        embeddings = [item.embedding for item in response.data]
        return np.array(embeddings, dtype=np.float32)

    def _save_index(self):
        """L∆∞u FAISS index v√† metadata ra disk."""
        if self.index is None:
            print("‚ö†Ô∏è Kh√¥ng c√≥ index ƒë·ªÉ l∆∞u")
            return

        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
        os.makedirs(os.path.dirname(self.index_path), exist_ok=True)

        # L∆∞u FAISS index
        faiss.write_index(self.index, self.index_path)

        # L∆∞u metadata
        metadata = {
            'product_ids': self.product_ids,
            'titles': self.titles
        }
        with open(self.metadata_path, 'wb') as f:
            pickle.dump(metadata, f)

        print(f"üíæ Saved index to {self.index_path}")
        print(f"üíæ Saved metadata to {self.metadata_path}")

    def _load_index(self):
        """Load FAISS index v√† metadata t·ª´ disk."""
        print("üìÇ Loading existing product index...")

        # Load FAISS index
        self.index = faiss.read_index(self.index_path)

        # Load metadata
        with open(self.metadata_path, 'rb') as f:
            metadata = pickle.load(f)
            self.product_ids = metadata['product_ids']
            self.titles = metadata['titles']

        print(f"‚úÖ Loaded product index with {self.index.ntotal} vectors")

    def _load_index_if_exists(self):
        """Load index n·∫øu file t·ªìn t·∫°i."""
        if os.path.exists(self.index_path) and os.path.exists(self.metadata_path):
            try:
                self._load_index()
            except Exception as e:
                print(f"‚ö†Ô∏è Error loading product index: {e}")
                print("üí° S·∫Ω build index khi g·ªçi update_index()")

    def vectorize_products(self, force_rebuild: bool = False):
        """
        Vector h√≥a products v√† l∆∞u v√†o b·∫£ng product_vectors.

        Flow m·ªõi:
        1. L·∫•y ·∫£nh n·ªÅn (ANH_NEN) c·ªßa products t·ª´ b·∫£ng images
        2. Ph√¢n t√≠ch ·∫£nh b·∫±ng LLM Vision ‚Üí text m√¥ t·∫£
        3. Embedding text m√¥ t·∫£
        4. L∆∞u v√†o product_vectors

        Args:
            force_rebuild: N·∫øu True, vector h√≥a l·∫°i t·∫•t c·∫£ products.
                          N·∫øu False, ch·ªâ vector h√≥a products m·ªõi (ch∆∞a c√≥ trong product_vectors).
        """
        connection = None
        try:
            connection = self._get_db_connection()
            cursor = connection.cursor(dictionary=True)

            if force_rebuild:
                # Vector h√≥a t·∫•t c·∫£ products (rebuild to√†n b·ªô)
                print("üîÑ Force rebuild - Vector h√≥a t·∫•t c·∫£ products...")

                # Query ƒë·ªÉ l·∫•y products v√† ·∫£nh n·ªÅn
                query = """
                    SELECT p.id, p.title, i.src as image_url
                    FROM products p
                    LEFT JOIN images i ON p.id = i.product_id AND i.name = 'ANH_NEN'
                """
                cursor.execute(query)
                products = cursor.fetchall()

                if not products:
                    print("‚ö†Ô∏è Kh√¥ng c√≥ products n√†o trong database!")
                    return

                print(f"üìö T√¨m th·∫•y {len(products)} products")

                # Ph√¢n t√≠ch ·∫£nh v√† t·∫°o embeddings
                product_ids = []
                embeddings_list = []
                success_count = 0
                fallback_count = 0

                for idx, product in enumerate(products, 1):
                    product_id = product['id']
                    title = product['title']
                    image_url = product.get('image_url')

                    print(f"üîÑ [{idx}/{len(products)}] Processing product {product_id}...", end=' ')

                    # N·∫øu c√≥ ·∫£nh n·ªÅn, ph√¢n t√≠ch b·∫±ng LLM
                    text_to_embed = None
                    if image_url:
                        llm_output = self._analyze_image_from_url(image_url)
                        if llm_output:
                            text_to_embed = self._create_description_text(llm_output)
                            print(f"‚úÖ LLM: {llm_output['product_name'][:50]}")
                            success_count += 1
                        else:
                            print(f"‚ö†Ô∏è LLM failed, fallback to title")
                            text_to_embed = title
                            fallback_count += 1
                    else:
                        print(f"‚ö†Ô∏è No image, fallback to title")
                        text_to_embed = title
                        fallback_count += 1

                    # T·∫°o embedding
                    embedding = self._create_embeddings_batch([text_to_embed])[0]

                    product_ids.append(product_id)
                    embeddings_list.append(embedding)

                # X√≥a t·∫•t c·∫£ vectors c≈©
                cursor.execute("DELETE FROM product_vectors")

                # Insert vectors m·ªõi
                insert_query = """
                    INSERT INTO product_vectors (product_id, vector)
                    VALUES (%s, %s)
                """
                for product_id, embedding in zip(product_ids, embeddings_list):
                    vector_json = json.dumps(embedding.tolist())
                    cursor.execute(insert_query, (product_id, vector_json))

                connection.commit()
                print(f"\n‚úÖ ƒê√£ vector h√≥a v√† l∆∞u {len(products)} products")
                print(f"   - LLM Vision: {success_count}")
                print(f"   - Fallback (title): {fallback_count}")

            else:
                # Ch·ªâ vector h√≥a products m·ªõi
                print("üîÑ Incremental update - Ch·ªâ vector h√≥a products m·ªõi...")

                query = """
                    SELECT p.id, p.title, i.src as image_url
                    FROM products p
                    LEFT JOIN product_vectors pv ON p.id = pv.product_id
                    LEFT JOIN images i ON p.id = i.product_id AND i.name = 'ANH_NEN'
                    WHERE pv.id IS NULL
                """
                cursor.execute(query)
                new_products = cursor.fetchall()

                if new_products:
                    print(f"üìö T√¨m th·∫•y {len(new_products)} products m·ªõi")

                    # Ph√¢n t√≠ch ·∫£nh v√† t·∫°o embeddings
                    product_ids = []
                    embeddings_list = []
                    success_count = 0
                    fallback_count = 0

                    for idx, product in enumerate(new_products, 1):
                        product_id = product['id']
                        title = product['title']
                        image_url = product.get('image_url')

                        print(f"üîÑ [{idx}/{len(new_products)}] Processing product {product_id}...", end=' ')

                        # N·∫øu c√≥ ·∫£nh n·ªÅn, ph√¢n t√≠ch b·∫±ng LLM
                        text_to_embed = None
                        if image_url:
                            llm_output = self._analyze_image_from_url(image_url)
                            if llm_output:
                                text_to_embed = self._create_description_text(llm_output)
                                print(f"‚úÖ LLM: {llm_output['product_name'][:50]}")
                                success_count += 1
                            else:
                                print(f"‚ö†Ô∏è LLM failed, fallback to title")
                                text_to_embed = title
                                fallback_count += 1
                        else:
                            print(f"‚ö†Ô∏è No image, fallback to title")
                            text_to_embed = title
                            fallback_count += 1

                        # T·∫°o embedding
                        embedding = self._create_embeddings_batch([text_to_embed])[0]

                        product_ids.append(product_id)
                        embeddings_list.append(embedding)

                    # Insert vectors
                    insert_query = """
                        INSERT INTO product_vectors (product_id, vector)
                        VALUES (%s, %s)
                    """
                    for product_id, embedding in zip(product_ids, embeddings_list):
                        vector_json = json.dumps(embedding.tolist())
                        cursor.execute(insert_query, (product_id, vector_json))

                    connection.commit()
                    print(f"\n‚úÖ ƒê√£ vector h√≥a v√† l∆∞u {len(new_products)} products m·ªõi")
                    print(f"   - LLM Vision: {success_count}")
                    print(f"   - Fallback (title): {fallback_count}")
                else:
                    print("‚úÖ Kh√¥ng c√≥ products m·ªõi n√†o c·∫ßn vector h√≥a")

        except Error as e:
            print(f"‚ùå L·ªói khi vector h√≥a products: {e}")
            if connection:
                connection.rollback()
            raise
        finally:
            if connection and connection.is_connected():
                cursor.close()
                connection.close()

    def build_index(self):
        """
        Build FAISS index t·ª´ b·∫£ng product_vectors.
        """
        connection = None
        try:
            print("üî® Building FAISS index t·ª´ product_vectors...")

            connection = self._get_db_connection()
            cursor = connection.cursor(dictionary=True)

            # L·∫•y t·∫•t c·∫£ vectors t·ª´ database
            query = """
                SELECT pv.product_id, p.title, pv.vector
                FROM product_vectors pv
                JOIN products p ON pv.product_id = p.id
                ORDER BY pv.product_id
            """
            cursor.execute(query)
            results = cursor.fetchall()

            if not results:
                print("‚ö†Ô∏è Kh√¥ng c√≥ vectors n√†o trong database!")
                print("üí° H√£y ch·∫°y vectorize_products() tr∆∞·ªõc")
                return

            print(f"üìö Loaded {len(results)} vectors t·ª´ database")

            # Parse vectors t·ª´ JSON
            vectors = []
            self.product_ids = []
            self.titles = []

            for row in results:
                vector_list = json.loads(row['vector'])
                vectors.append(vector_list)
                self.product_ids.append(row['product_id'])
                self.titles.append(row['title'])

            # Convert sang numpy array
            vectors_array = np.array(vectors, dtype=np.float32)

            # T·∫°o FAISS index
            self.index = faiss.IndexFlatL2(self.dimension)
            self.index.add(vectors_array)

            print(f"‚úÖ Index built v·ªõi {self.index.ntotal} vectors")

            # L∆∞u index v√† metadata ra file
            self._save_index()

        except Error as e:
            print(f"‚ùå L·ªói khi build index: {e}")
            raise
        finally:
            if connection and connection.is_connected():
                cursor.close()
                connection.close()

    def update_index(self, force_rebuild: bool = False):
        """
        Update FAISS index (vector h√≥a products + rebuild index).

        Args:
            force_rebuild: N·∫øu True, vector h√≥a l·∫°i t·∫•t c·∫£ products (d√πng cho /build-product-index)
                          N·∫øu False, ch·ªâ vector h√≥a products m·ªõi (d√πng cho /update-product-index)
        """
        print("=" * 60)
        if force_rebuild:
            print("üî® BUILDING PRODUCT INDEX (Force Rebuild)")
        else:
            print("üîÑ UPDATING PRODUCT INDEX (Incremental)")
        print("=" * 60)

        # B∆∞·ªõc 1: Vector h√≥a products
        self.vectorize_products(force_rebuild=force_rebuild)

        # B∆∞·ªõc 2: Rebuild index
        self.build_index()

        print("=" * 60)
        print("‚úÖ Index updated successfully!")
        print("=" * 60)

    def get_stats(self) -> Dict:
        """L·∫•y th·ªëng k√™ v·ªÅ index."""
        connection = None
        try:
            connection = self._get_db_connection()
            cursor = connection.cursor()

            # ƒê·∫øm s·ªë products
            cursor.execute("SELECT COUNT(*) FROM products")
            total_products = cursor.fetchone()[0]

            # ƒê·∫øm s·ªë vectors
            cursor.execute("SELECT COUNT(*) FROM product_vectors")
            total_vectors = cursor.fetchone()[0]

            stats = {
                'total_products': total_products,
                'total_vectors': total_vectors,
                'vectorized_percentage': round((total_vectors / total_products * 100), 2) if total_products > 0 else 0,
                'dimension': self.dimension,
                'model': self.embedding_model
            }

            if self.index:
                stats['index_size'] = self.index.ntotal

            return stats

        except Error as e:
            print(f"‚ùå L·ªói khi l·∫•y stats: {e}")
            return {}
        finally:
            if connection and connection.is_connected():
                cursor.close()
                connection.close()
