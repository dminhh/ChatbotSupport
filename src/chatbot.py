"""
Chatbot há»— trá»£ FAQ cho ecommerce sá»­ dá»¥ng RAG (Retrieval-Augmented Generation).

Flow:
1. User há»i cÃ¢u há»i
2. Vector search tÃ¬m top-k FAQs liÃªn quan
3. Build context tá»« FAQs
4. Gá»­i context + question vÃ o GPT
5. GPT generate cÃ¢u tráº£ lá»i tá»± nhiÃªn
"""

import os
from typing import Dict, List, Optional
from openai import OpenAI
from dotenv import load_dotenv
from vector_search import VectorSearch

# Load environment variables
load_dotenv()


class ChatbotRAG:
    """Chatbot sá»­ dá»¥ng RAG Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i vá» ecommerce."""

    def __init__(
        self,
        knowledge_base_path: str = "data/knowledge_base.json",
        index_path: str = "data/faiss_index.bin",
        similarity_threshold: float = 0.6,
        top_k: int = 3,
        model: str = "gpt-3.5-turbo"
    ):
        """
        Khá»Ÿi táº¡o chatbot.

        Args:
            knowledge_base_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file knowledge base JSON
            index_path: ÄÆ°á»ng dáº«n Ä‘áº¿n FAISS index
            similarity_threshold: NgÆ°á»¡ng similarity Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¢u há»i cÃ³ relevant khÃ´ng (0-1)
            top_k: Sá»‘ lÆ°á»£ng FAQs liÃªn quan nháº¥t Ä‘á»ƒ retrieve
            model: Model OpenAI GPT Ä‘á»ƒ sá»­ dá»¥ng
        """
        self.vector_search = VectorSearch(knowledge_base_path, index_path)
        self.similarity_threshold = similarity_threshold
        self.top_k = top_k
        self.model = model

        # Khá»Ÿi táº¡o OpenAI client
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY khÃ´ng tÃ¬m tháº¥y trong environment variables")

        self.client = OpenAI(api_key=api_key)

        # Template cho fallback response
        self.fallback_response = """Xin lá»—i, tÃ´i chÆ°a hiá»ƒu rÃµ cÃ¢u há»i cá»§a báº¡n.

Báº¡n cÃ³ thá»ƒ há»i vá»:
â€¢ ChÃ­nh sÃ¡ch Ä‘á»•i tráº£
â€¢ Thá»i gian váº­n chuyá»ƒn
â€¢ PhÆ°Æ¡ng thá»©c thanh toÃ¡n
â€¢ HÆ°á»›ng dáº«n chá»n size

Hoáº·c liÃªn há»‡:
ğŸ“ Hotline: 1900-xxxx"""

    def _build_context(self, search_results: List[Dict]) -> str:
        """
        Build context tá»« káº¿t quáº£ search.

        Args:
            search_results: List cÃ¡c FAQs tá»« vector search

        Returns:
            Context string Ä‘á»ƒ gá»­i cho GPT
        """
        if not search_results:
            return ""

        context_parts = []
        for i, result in enumerate(search_results, 1):
            context_parts.append(
                f"FAQ {i} (Äá»™ liÃªn quan: {result['similarity']:.2f}):\n"
                f"CÃ¢u há»i: {result['question']}\n"
                f"Tráº£ lá»i: {result['answer']}\n"
                f"Danh má»¥c: {result['category']}"
            )

        return "\n\n".join(context_parts)

    def _generate_response_stream(self, question: str, context: str):
        """
        Sá»­ dá»¥ng GPT Ä‘á»ƒ generate cÃ¢u tráº£ lá»i tá»± nhiÃªn vá»›i streaming.

        Args:
            question: CÃ¢u há»i cá»§a user
            context: Context tá»« FAQs

        Yields:
            Tá»«ng chunk cá»§a cÃ¢u tráº£ lá»i
        """
        system_prompt = """Báº¡n lÃ  trá»£ lÃ½ áº£o thÃ´ng minh cá»§a má»™t trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ Viá»‡t Nam.

PHáº M VI HOáº T Äá»˜NG:
- CHá»ˆ há»— trá»£ cÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n mua sáº¯m trá»±c tuyáº¿n: Ä‘Æ¡n hÃ ng, váº­n chuyá»ƒn, thanh toÃ¡n, sáº£n pháº©m, Ä‘á»•i tráº£, khuyáº¿n mÃ£i...
- CHá»ˆ tráº£ lá»i small talk CÆ  Báº¢N: chÃ o há»i, táº¡m biá»‡t, cáº£m Æ¡n
- TUYá»†T Äá»I KHÃ”NG tráº£ lá»i vá»: thá»ƒ thao, chÃ­nh trá»‹, giáº£i trÃ­, thá»i tiáº¿t, hay Báº¤T Ká»² chá»§ Ä‘á» nÃ o NGOÃ€I ecommerce

CÃCH Xá»¬ LÃ:
1. Náº¿u cÃ³ FAQs liÃªn quan: Dá»±a vÃ o FAQs Ä‘á»ƒ tráº£ lá»i má»™t cÃ¡ch tá»± nhiÃªn, thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p
2. Náº¿u lÃ  lá»i chÃ o/táº¡m biá»‡t/cáº£m Æ¡n cÆ¡ báº£n: ChÃ o láº¡i thÃ¢n thiá»‡n, giá»›i thiá»‡u báº¡n lÃ  trá»£ lÃ½ mua sáº¯m, há»i cÃ³ thá»ƒ giÃºp gÃ¬ vá» Ä‘Æ¡n hÃ ng/sáº£n pháº©m
3. Náº¿u lÃ  cÃ¢u há»i ngoÃ i pháº¡m vi ecommerce (VD: Ronaldo hay Messi, thá»i tiáº¿t hÃ´m nay...): Lá»‹ch sá»± Tá»ª CHá»I, nÃ³i báº¡n chá»‰ há»— trá»£ vá» mua sáº¯m, gá»£i Ã½ khÃ¡ch hÃ ng há»i vá» Ä‘Æ¡n hÃ ng/sáº£n pháº©m
4. Náº¿u khÃ´ng cÃ³ FAQs cho cÃ¢u há»i vá» ecommerce: NÃ³i báº¡n chÆ°a cÃ³ thÃ´ng tin nÃ y, gá»£i Ã½ liÃªn há»‡ hotline 1900-xxxx

QUY Táº®C QUAN TRá»ŒNG:
- KHÃ”NG bá»‹a thÃ´ng tin khÃ´ng cÃ³ trong FAQs
- Tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch, dá»… hiá»ƒu
- Sá»­ dá»¥ng emoji má»™t cÃ¡ch tinh táº¿ náº¿u phÃ¹ há»£p
- GIá»® ÄÃšNG PHáº M VI: Chá»‰ ecommerce + small talk cÆ¡ báº£n"""

        user_prompt = f"""CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {question}

CÃ¡c FAQs liÃªn quan:
{context}

HÃ£y tráº£ lá»i cÃ¢u há»i cá»§a khÃ¡ch hÃ ng dá»±a trÃªn cÃ¡c FAQs trÃªn."""

        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=500,
                stream=True
            )

            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    yield chunk.choices[0].delta.content

        except Exception as e:
            print(f"Lá»—i khi gá»i OpenAI API: {e}")
            yield "Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra. Vui lÃ²ng thá»­ láº¡i sau."

    def chat_stream(self, question: str):
        """
        Xá»­ lÃ½ cÃ¢u há»i cá»§a user vÃ  tráº£ vá» cÃ¢u tráº£ lá»i dáº¡ng stream.

        Args:
            question: CÃ¢u há»i cá»§a user

        Yields:
            Tá»«ng chunk cá»§a cÃ¢u tráº£ lá»i
        """
        # BÆ°á»›c 1 & 2: Vector search tÃ¬m top-k FAQs liÃªn quan
        search_results = self.vector_search.search(
            query=question,
            top_k=self.top_k
        )

        # Kiá»ƒm tra xem cÃ³ FAQ nÃ o Ä‘á»§ relevant khÃ´ng
        relevant_results = [
            r for r in search_results
            if r['similarity'] >= self.similarity_threshold
        ]

        # BÆ°á»›c 3: Build context tá»« FAQs
        if relevant_results:
            context = self._build_context(relevant_results)
        else:
            # KhÃ´ng cÃ³ FAQs relevant, GPT sáº½ tá»± xá»­ lÃ½ (small talk hoáº·c tá»« chá»‘i)
            context = "(KhÃ´ng cÃ³ FAQs liÃªn quan)"

        # BÆ°á»›c 4 & 5: Stream response tá»« GPT
        # GPT sáº½ tá»± xá»­ lÃ½ cáº£ small talk vÃ  tá»« chá»‘i cÃ¢u há»i ngoÃ i scope
        for chunk in self._generate_response_stream(question, context):
            yield chunk

    def rebuild_index(self):
        """Rebuild FAISS index khi knowledge base Ä‘Æ°á»£c cáº­p nháº­t."""
        self.vector_search.rebuild_index()
        print("âœ“ Index Ä‘Ã£ Ä‘Æ°á»£c rebuild thÃ nh cÃ´ng!")

    def get_stats(self) -> Dict:
        """Láº¥y thá»‘ng kÃª vá» vector search index."""
        return self.vector_search.get_stats()


def main():
    """Test chatbot vá»›i má»™t sá»‘ cÃ¢u há»i máº«u."""
    print("=" * 60)
    print("ğŸ¤– CHATBOT ECOMMERCE - RAG DEMO")
    print("=" * 60)

    # Khá»Ÿi táº¡o chatbot
    try:
        chatbot = ChatbotRAG(
            knowledge_base_path="data/knowledge_base.json",
            index_path="data/faiss_index.bin",
            similarity_threshold=0.6,
            top_k=3
        )

        # In thá»‘ng kÃª
        stats = chatbot.get_stats()
        print(f"\nğŸ“Š Thá»‘ng kÃª: {stats['num_questions']} cÃ¢u há»i trong knowledge base")
        print(f"ğŸ”§ Model: {chatbot.model}")
        print(f"ğŸ¯ Similarity threshold: {chatbot.similarity_threshold}")

    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi táº¡o chatbot: {e}")
        return

    # Danh sÃ¡ch cÃ¢u há»i test
    test_questions = [
        "TÃ´i muá»‘n biáº¿t vá» chÃ­nh sÃ¡ch giao hÃ ng",
        "LÃ m sao Ä‘á»ƒ thanh toÃ¡n khi mua hÃ ng?",
        "Sáº£n pháº©m bá»‹ lá»—i thÃ¬ Ä‘á»•i nhÆ° tháº¿ nÃ o?",
        "LÃ m tháº¿ nÃ o Ä‘á»ƒ mua xe mÃ¡y?"  # CÃ¢u há»i khÃ´ng liÃªn quan Ä‘á»ƒ test fallback
    ]

    # Test tá»«ng cÃ¢u há»i
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'=' * 60}")
        print(f"â“ CÃ¢u há»i {i}: {question}")
        print("-" * 60)

        print(f"\nğŸ’¬ Tráº£ lá»i:")
        for chunk in chatbot.chat_stream(question):
            print(chunk, end='', flush=True)
        print()  # Newline sau khi stream xong

    print(f"\n{'=' * 60}")
    print("âœ… Demo hoÃ n táº¥t!")
    print("=" * 60)


if __name__ == "__main__":
    main()
